# 模型配置
model_cfgs:
  model_name_or_path: "llava-hf/llava-1.5-7b-hf"  # 基础模型路径（可替换为Alpaca衍生模型）
  model_max_length: 512
  trust_remote_code: False
  padding_side: "right"

# 训练配置
train_cfgs:
  epochs: 3
  batch_size: 8
  learning_rate: 2e-5
  weight_decay: 0.01
  gradient_checkpointing: True
  regularization: 0.01  # 正则化强度
  eval_strategy: "steps"
  eval_interval: 100  # 每100步评估一次
  seed: 42
  processor_kwargs: {}

# 数据配置
data_cfgs:
  train_datasets: ["data/helpful_train.jsonl"]  # Helpful训练数据集
  eval_datasets: ["data/helpful_eval.jsonl"]   # Helpful评估数据集
  max_samples: -1  # 全部样本训练
  num_workers: 4

# 日志与保存配置
logger_cfgs:
  save_interval: 500  # 每500步保存一次模型
  output_dir: "output/helpful_reward_model"  # Helpful模型保存路径
  log_dir: "logs/helpful"
  report_to: ["tensorboard"]

# DeepSpeed配置（分布式训练）
deepspeed:
  train_batch_size: "auto"
  train_micro_batch_size_per_gpu: 2
  zero_optimization:
    stage: 2
    offload_optimizer:
      device: "cpu"
    offload_param:
      device: "cpu"
  gradient_accumulation_steps: "auto"
  fp16:
    enabled: True